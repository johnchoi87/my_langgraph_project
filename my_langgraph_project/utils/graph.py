import os

from langchain_google_community import GooglePlacesTool
from langchain_openai import ChatOpenAI
from langgraph.constants import START, END
from langgraph.graph import StateGraph, MessagesState
from langchain_community.utilities import OpenWeatherMapAPIWrapper

from dotenv import load_dotenv
from langchain_core.tools import tool

from langgraph.prebuilt import ToolNode
import streamlit as st
import googlemaps

load_dotenv()
# Google Maps API í‚¤ ì„¤ì •
key = os.getenv("GMAPS_API_KEY")
gmaps = googlemaps.Client(key=key)


# LangChain Tool ì •ì˜
@tool
def get_weather(location: str):
    """Call to get the current weather."""
    with st.spinner("ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤."):
        weather = OpenWeatherMapAPIWrapper()
        weather_data = weather.run(location)
        # print(weather_data)
    return weather_data


@tool
# def get_places(location: str, category: str):
def get_places(query: str):
    """Get a list of places"""
    with st.spinner("ì¥ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤."):
        places = GooglePlacesTool()
        places_data = places.run(query)
        # print(places_data)
    return places_data


tools = [get_weather, get_places]

tool_node = ToolNode(tools)
model_with_tools = ChatOpenAI(model="gpt-4o", temperature=0).bind_tools(tools)


def should_continue(state: MessagesState):
    messages = state["messages"]
    last_message = messages[-1]
    if last_message.tool_calls:
        return "tools"
    return END


def call_model(state: MessagesState):
    print(state)
    messages = state["messages"]
    # í”„ë¡¬í”„íŠ¸ì— ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ì—¬ ë” ì¹œê·¼í•˜ê³  ìƒë™ê° ìˆê²Œ ë§Œë“¦ ğŸ¨âœ¨
    '''
    messages.append({
        "role": "system",
        "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ì¾Œí•œ AIì…ë‹ˆë‹¤! ğŸ¤–ğŸ’¡ë‹µë³€ì— ì´ëª¨ì§€ë¥¼ ì ê·¹ í™œìš©í•˜ê³ , ëª…í™•í•˜ê³  ê°„ê²°í•œ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”! í•œê¸€ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”!ğŸš€ğŸ”¥"
                   "ì‚¬ìš©ìê°€ íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ìš”ì²­í•˜ë©´, í•´ë‹¹ ë„ì‹œ ì´ë¦„ì„ ì˜ì–´ë¡œ ë³€í™˜í•˜ì—¬ get_weather ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”. "
                   "ì˜ˆ: 'ì„œìš¸ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜' -> get_weather(location='seoul')"
                   "ì‚¬ìš©ìê°€ íŠ¹ì • ë„ì‹œì˜ ê·¼ì²˜ ì¥ì†Œë¥¼ ìš”ì²­í•˜ë©´, í•´ë‹¹ ë„ì‹œ ì´ë¦„ì„ ì˜ì–´ë¡œ ë³€í™˜í•˜ì—¬ get_places ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”. "
                   "ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ë„ì‹œëª…ì´ ìˆìœ¼ë©´ ì¢Œí‘œ ì •ë³´ëŠ” ë¬´ì‹œí•´ì¤˜"
                   "ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ë„ì‹œì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìœ¼ë©´ get_city_from_coordinates ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ì‹œ ì´ë¦„ì„ ì°¾ì•„ì£¼ì„¸ìš”. "
    })
    '''
    with st.spinner("AIê°€ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤."):
        response = model_with_tools.invoke(messages)
    # print(response)
    return {"messages": [response]}


def create_workflow():
    workflow = StateGraph(MessagesState)

    workflow.add_node("agent", call_model)
    workflow.add_node("tools", tool_node)

    workflow.add_edge(START, "agent")
    workflow.add_conditional_edges("agent", should_continue, ["tools", END])
    workflow.add_edge("tools", "agent")

    app = workflow.compile()
    return app


if __name__ == "__main__":
    app = create_workflow()
    app.get_graph().draw_mermaid_png(output_file_path="workflow.png")
    '''
    for chunk in app.stream(
        # {"messages": [("human", "ë¶„ë‹¹ ë‚ ì”¨ëŠ”?")]}, stream_mode="values"
        # {"messages": [("human", "ë™ëŒ€ë¬¸êµ¬ ì¥ì•ˆ1ë™ ê·¼ì²˜ ì•„íŒŒíŠ¸?")]},
        # {"messages": [("human", "ì˜¤ëŠ˜ ì„œìš¸ì—ì„œ ìš´ë™í•˜ê¸° ë‚ ì”¨ê°€ ì–´ë•Œ?")]},
        # {"messages": [("human", "ì—¬ì˜ë„ì—ì„œ ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬ ë§›ì§‘ì„ ì†Œê°œí•´ì¤˜")]},
        {"messages": [("human", "í˜„ì¬ ì„œìš¸ì—ì„œ ì—°ë‚ ë¦¬ê¸° í•˜ê¸°ì— ì–´ë–„? coord:127.269311. 37.413294")]}, stream_mode="values"):
        chunk["messages"][-1].pretty_print()
'''
